{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code gives a procedure that takes as its input a WeatherUnderground station ID.  It puts in a \"condition request\" for that station, and grabs a list of the nearby stations.  You can inductively build a data-set of all nearby stations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## this allows us to build a C-like `struct' object\n",
    "from collections import namedtuple\n",
    "## this allows us to load up web pages and read them\n",
    "import urllib2\n",
    "## this is a library for parsing JSON files.  JSON stands for JavaScript Object Notation. It\n",
    "## is a common ASCII text file for describing structured data. \n",
    "import json\n",
    "## we will need to put delays in between our requests to web pages.  Popular web-pages\n",
    "## will block your access if you request too much data too quickly.\n",
    "import time \n",
    "## for writing out own json files\n",
    "import simplejson\n",
    "\n",
    "## These routines need a Weather Underground API.  You will need to request one from the Weather Underground webpage\n",
    "## to do your own scraping. If you use my one below, you will quickly be locked out. \n",
    "WAPI = \"your.key.here\"\n",
    "\n",
    "## \"WeatherStructure\" is the name of this data type. \n",
    "## If X is a WStruct, you can call its attributes by: x.StationID, x.assoc, etc. \n",
    "WStruct = namedtuple(\"WeatherStructure\", \"StationID assoc neighbourhood city province country lat lon elev time weather temp_c humid wind_string wind_dir wind_deg wind_kph pressure_mb dewpt_c precip_today\")\n",
    "## StationID is the Wunderground station ID code\n",
    "## assoc is the associated nearby Wunderground station ID's\n",
    "## neighbourhood is a text string indicating roughly where the station is\n",
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Give this routine a station ID, it will return a WStruct associated to the station\n",
    "def FetchWeather(fStationID):\n",
    "    URL_string = \"http://api.wunderground.com/api/\"+WAPI+\"/geolookup/conditions/q/pws:\"+fStationID+\".json\"\n",
    "    print fStationID,\n",
    "    URLobj = urllib2.urlopen(URL_string)\n",
    "    print \". \",\n",
    "    json_string = URLobj.read()\n",
    "    parsed_json = json.loads(json_string) ## This creates an index for reading the file\n",
    "    \n",
    "    # We will use this dictionary-object to build the retval, a WStruct type. \n",
    "    adj_pws_stations = parsed_json['location']['nearby_weather_stations']['pws']['station']\n",
    "    nearby_stations = [ adj_pws_stations[i]['id'] for i in range(len(adj_pws_stations)) ]\n",
    "    \n",
    "    # Return the WStruct\n",
    "    return WStruct(StationID = fStationID, assoc = nearby_stations, neighbourhood = adj_pws_stations[0]['neighborhood'], city = parsed_json['current_observation']['display_location']['city'], province = parsed_json['current_observation']['display_location']['state_name'], country = parsed_json['current_observation']['display_location']['country'], lat = parsed_json['current_observation']['display_location']['latitude'], lon = parsed_json['current_observation']['display_location']['longitude'], elev = parsed_json['current_observation']['display_location']['elevation'], time = parsed_json['current_observation']['observation_time'], weather = parsed_json['current_observation']['weather'], temp_c = parsed_json['current_observation']['temp_c'], humid = parsed_json['current_observation']['relative_humidity'], wind_string = parsed_json['current_observation']['wind_string'],wind_dir = parsed_json['current_observation']['wind_dir'], wind_deg = parsed_json['current_observation']['wind_degrees'], wind_kph = parsed_json['current_observation']['wind_kph'], pressure_mb = parsed_json['current_observation']['pressure_mb'], dewpt_c = parsed_json['current_observation']['dewpoint_c'], precip_today = parsed_json['current_observation']['precip_today_metric'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep a list of stations we've already queried\n",
    "StationsVisited = []\n",
    "# And a list of stations we've discovered but not queried. We give it an initial seed.\n",
    "StationsUnexplored = [\"IBRITISH479\"]\n",
    "# List of fetched weather station data. \n",
    "WeatherStationData = []\n",
    "\n",
    "## Run through only the *newly discovered* weather stations, and poll\n",
    "## them, building the list of weather station data. \n",
    "\n",
    "def buildStationData():\n",
    "    print \"Fetching weather from station: \",\n",
    "    global StationsUnexplored\n",
    "    tempUnexplored = []\n",
    "    for i in range(len(StationsUnexplored)):\n",
    "        WS = FetchWeather(StationsUnexplored[i])\n",
    "        time.sleep(6) ## be nice!\n",
    "        WeatherStationData.append(WS)\n",
    "        StationsVisited.append(WS.StationID)\n",
    "        \n",
    "        ## let's start building the new unexplored list..\n",
    "        for j in range(len(WS.assoc)):\n",
    "            if (WS.assoc[j] not in StationsVisited) and (WS.assoc[j] not in StationsUnexplored) and (WS.assoc[j] not in tempUnexplored):\n",
    "                tempUnexplored.append(WS.assoc[j])\n",
    "    print(\"\\n\")\n",
    "    StationsUnexplored = list(tempUnexplored)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather from station:  IBRITISH254 .  IBRITISH446 .  IBRITISH420 .  IBCNANAI28 .  IBCDELTA19 .  IBCDELTA9 .  IBCDELTA13 .  IBCLADNE1 .  IBCGABRI2 .  MC4635 .  KWAPORTA54 .  KWAPORTA20 .  KWAPORTA14 .  KWAPORTA50 .  KWAPORTA34 .  KWAPORTA5 .  KWAPORTA48 .  KWAPORTA11 .  KWAPORTA38 .  MAS234 .  MAT319 .  KWASEQUI57 .  KWASEQUI32 .  KWASEQUI36 .  KWASEQUI67 .  KWASEQUI45 .  KWASEQUI53 .  KWASEQUI29 .  KWASEQUI60 .  KWAPORTA29 .  KWASEQUI44 .  KWASEQUI55 .  KWASEKIU2 .  KWAOLGA3 .  KWAOLGA4 .  KWAEASTS16 .  KWALUMMI2 .  KWALUMMI8 .  KWAFERND4 .  KWAFERND31 .  KWABELLI17 .  KWABIRCH3 .  KWAANACO23 .  KWAANACO25 .  KWAANACO28 .  KWAANACO1 .  KWAANACO24 .  KWAANACO40 .  KWAANACO48 .  KWAANACO5 .  KWAANACO17 .  KWAANACO34 .  KWAANACO45 .  KWAANACO35 .  KWAANACO47 .  KWAANACO46 .  KWAANACO44 .  KWAANACO8 .  KWAOAKHA33 .  KWAOAKHA10 .  KWAANACO18 .  KWAANACO10 .  IBCSURRE87 .  IBCSURRE38 .  IBCRICHM12 .  IBCWHITE8 .  IBRITISH442 .  IBCRICHM23 .  IBCDELTA15 .  IBCWHITE4 .  IBCWHITE3 .  IBRITISH386 .  IBCRICHM10 .  IBCDELTA17 .  IBCSURRE79 .  IBCSURRE53 .  IBCRICHM19 .  IBCRICHM29 .  IBCSURRE40 .  IBRITISH346 .  KWABLAIN16 .  IBCSURRE49 .  IBRITISH219 .  IBRITISH192 .  IBCNANAI9 .  IBRITISH47 .  IBCNANAI10 .  IBCNANAI15 .  IBCNANAI26 .  IBCNANAI19 .  IBCNANAI6 .  IBCNANAI24 .  IBCNANAI20 .  IBCNANAI22 .  IBCNANAI30 .  \n",
      "\n",
      "Explored:  205 Unexplored:  184 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## This block you can execute as many times as you like, to buildup your station readings.\n",
    "# on iteration, the list size grows roughly like: 1, 23, 67, 116... at which point we're \n",
    "# up in Duncan already.  At the next stage we'd be in Vancouver and Port Angeles.\n",
    "buildStationData()\n",
    "print(\"Explored: \", len(StationsVisited), \"Unexplored: \", len(StationsUnexplored), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's do a plot of altitude vs temperature. \n",
    "%matplotlib inline \n",
    "## the above forces figures to stay in the browser window. \n",
    "from matplotlib import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xax = [float(WeatherStationData[i].elev) for i in range(len(WeatherStationData))]\n",
    "yax = [float(WeatherStationData[i].temp_c) for i in range(len(WeatherStationData))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Dump a list of 4-tuples to a file, for future linear regression\n",
    "elevV = [float(WeatherStationData[i].elev) for i in range(len(WeatherStationData))]\n",
    "humidV = [float(WeatherStationData[i].humid.replace(\"%\", \"\")) for i in range(len(WeatherStationData))]\n",
    "windspV = [float(WeatherStationData[i].wind_kph) for i in range(len(WeatherStationData))]\n",
    "tempV = [float(WeatherStationData[i].temp_c) for i in range(len(WeatherStationData))]\n",
    "dumpV = zip(elevV, humidV, windspV, tempV)\n",
    "\n",
    "f = open('elev.humid.windsp.temp.Jan21.205.txt','w')\n",
    "simplejson.dump(dumpV, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(xax,yax, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## As we can see, some of the elevation readings are anomalous. \n",
    "## We can delete those entries for the purpose of our graphic.\n",
    "## Google has a service that estimates altitude on the earth's surface\n",
    "## by lat and long coordinates.  I believe it uses satellite imagery to \n",
    "## make this determination -- this is how Google indicates the altitude\n",
    "## of objects on Google earth.  So if we wanted to we could correct\n",
    "## the altitudes in the above data. Google Earth's data appears to be\n",
    "## accurate to only 10m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rxax = [float(xax[i]) for i in range(len(xax)) if (float(xax[i])>-10.0)]\n",
    "ryax = [float(yax[i]) for i in range(len(xax)) if (float(xax[i])>-10.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(rxax,ryax, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## We can save our data to human-readable text-file\n",
    "import simplejson\n",
    "f = open('temp-vs-alt.jan21.afternoon.txt','w')\n",
    "simplejson.dump([xax, yax], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## And we can load it back later. \n",
    "f = open('temp-vs-alt.jan21.txt','r')\n",
    "[l1,l2] = simplejson.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's consider doing some basic statistical analysis of the patterns here. \n",
    "## Linear Regression (see Wikipedia) can be used to find a unique line that is\n",
    "## a `best fit' for the data. This means the sum of the distances of the points from\n",
    "## the `regression line' is minimal... in a fairly specific sense. \n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(rxax, ryax)\n",
    "plt.plot(rxax,ryax,'ro')\n",
    "linfunc = intercept + rxax*slope\n",
    "plt.plot([0.0, 250.0], [intercept, 250.0*slope+intercept], 'y-') ## Add the regression line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## One can as for a quantification of \"how good\" the above fit is. \n",
    "print(\"p-value: \", p_value)\n",
    "print(\"R-value: \", r_value)\n",
    "print(\"std_err: \", std_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R$-value is defined as \n",
    "$$ R^2 = \\frac{\\sum_i (\\hat y_i - \\overline{y})^2}{\\sum (y_i - \\overline{y})^2}$$\n",
    "where $y_i$ are the observed $y$-values, $\\overline{y}$ is their mean, and $\\hat y_i$ is the fitted $y$-values, i.e. the linear function above evaluated at the $x_i$ coordinates. So the $R$-value is highly scale dependent, but gives a clear idea of whether or not the predicted and measured quantities $\\hat y_i$ and $y_i$ respectively have similar variation about the mean. \n",
    "\n",
    "The $p$-value measures confidence that the slope is horizontal.  It is a number between $0$ and $1$, it is $1$ when there is fair certainty the fitting line could be horizontal.  It is $0$ (or close to $0$) when there is (good) certainty the slope is non-zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
